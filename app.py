import streamlit as st
from logic import get_wikipedia_summary
import pandas as pd
from datetime import datetime
import os

HISTORY_FILE = r"C:\AIprogramming\streamlit\kadai2\log\search_history.csv"

def save_search_to_csv(keyword, result):
    if result is None:
        return

    data = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "keyword": keyword,
        "title": result["title"],
        "url": result["content_urls"]
    }

    df = pd.DataFrame([data])

    if os.path.exists(HISTORY_FILE):
        df.to_csv(HISTORY_FILE, mode='a', header=False, index=False)
    else:
        df.to_csv(HISTORY_FILE, mode='w', header=True, index=False)

st.title("ğŸ“š Wikipediaè¦ç´„æ¤œç´¢ã‚¢ãƒ—ãƒª")

query = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: å¯Œå£«å±±ï¼‰")

if st.button("æ¤œç´¢"):
    if not query.strip():
        st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        result = get_wikipedia_summary(query.strip())
        if result:
            save_search_to_csv(query.strip(), result)
            st.subheader(result["title"])
            if result["thumbnail"]:
                st.image(result["thumbnail"], width=200)
            if result["description"]:
                st.caption(result["description"])
            st.write(result["extract"])
            if result["content_urls"]:
                st.markdown(f"[Wikipediaè¨˜äº‹å…¨æ–‡ã¯ã“ã¡ã‚‰]({result['content_urls']})")
        else:
            st.error("è©²å½“ã™ã‚‹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# æ¤œç´¢å±¥æ­´ã‚’è¡¨ç¤º
st.markdown("---")
if st.checkbox("ğŸ” æ¤œç´¢å±¥æ­´ã‚’è¡¨ç¤º"):
    if os.path.exists(HISTORY_FILE):
        history_df = pd.read_csv(HISTORY_FILE)
        st.dataframe(history_df)
    else:
        st.info("æ¤œç´¢å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

